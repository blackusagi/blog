NEED:
1.爬虫中间件和下载中间件的作用
2.如何设置middlewares

GET：
1. 中间件作用
  1.1.中间件可以对爬取过程中非状态码 status !== 200的request对象进行重试；
  1.2.可以对cookie和headers进行更换和处理；

2.中间件的使用
    import random
    from tencent.settings import USER_AGENTS_LIST # 注意导入路径,请忽视pycharm的错误提示

    class UserAgentMiddleware(object):
        def process_request(self, request, spider):
            user_agent = random.choice(USER_AGENTS_LIST)
            request.headers['User-Agent'] = user_agent


    class CheckUA:
        def process_request(self,request,spider):
            pass
        
        def process_response(self,request,response,spider):
            if spider.name == "tencent"
               print(request.headers["User-Agent"])
               return response
    
    class ProxyMiddleware(self,request,spider):
            def process_request(self,request,spider):
                proxy = "http://1270.0.0.1:8080"
                # proxy = random.choice(proxies) # proxies可以在settings.py中，也可以来源于代理ip的webapi
                request.meta["proxy"] = proxy
                return None
    
    process_request(self,request,spider):
      每个request通过下载中间件时，方法被调用；
      可以注释默认的下载中间件和爬虫中间件；
    
    process_response(self,request,response,spider):
      放下载器完成http请求，传递相应给引擎的时候调用
 
 3.在setting中配置
      ROBOTSTXT_OBEY = False
      DOWNLOADER_MIDDLEWARES = {
          'Tencent.middlewares.UserAgentMiddleware': 543,
          'Tencent.middlewares.CheckUA': 600,
          'Tencent.middlewares.ProxyMiddleware': 550,
      }

4.scrapy中有那些中间件
  1.schduler midleware 
    一般用不到；
  2.spider midleware爬虫中间件
    爬虫在运行的过程中进行处理；
  3.download midleware下载中间件
    请求到网页后，下载时做一些处理；
  
  
    
