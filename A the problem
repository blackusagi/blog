[2018-11-28]

NEED:
1.线程、多线程、多进程、携程、线程池、消息队列、守护线程、阻塞、主线程；
2.改良链家、机场爬虫速度；
3.爬虫启动成功或失败通知到邮箱或者其他地址上；

GET:
1.jsonpath模块

  from jsonpath import jsonpath
  data = {}  # type(data) = dict
  print(jsonpath(data,"$..author"))
  
2.post请求+保存seesion

  data = {"key1":"value1"}
  s = requests.session  
  s.post(url,data=data,headers=headers)

3.请求失败重试+assert断言错误

  from retrying import retry
  
  @retry(stop_max_attempt_number=3)
  def parse_url(url):
    resp = requests.get(url,headers=header,timeout=2)
    assert resp.status_code == 200
    return resp
  
  def paser(url):
    try:
      resp = parse_url(url)
      execept Exception as e:
        print(e)
        resp = None
    return resp
    
  if __name__ == "__main__":
    url = ""
    resp = paser(url)
    print(resp)
  
  stop_max_attempt_number：最大重试次数，超过该次数就停止；
  stop_max_delay: 单位毫秒，被装饰的函数开始执行的时间点开始，到函数成功运行结束或者失败报错中止的时间点，只要这段时间超过10秒，函数就不会再执行了；
  wait_fixed: 设置两次重试的时间间隔；
  wait_random_min和wait_random_max: 用随机的方式设置两次重试之间的间隔；
  
4.制造随机请求头

  import random
  
  def random_ua():
      first_num = random.randint(55, 62)
      third_num = random.randint(0, 3200)
      fourth_num = random.randint(0, 140)
      os_type = [
        '(Windows NT 6.1; WOW64)', '(Windows NT 10.0; WOW64)', '(X11; Linux x86_64)',
        '(Macintosh; Intel Mac OS X 10_12_6)'
      ]
      chrome_version = 'Chrome/{}.0.{}.{}'.format(first_num, third_num, fourth_num)
      ua = ' '.join(['Mozilla/5.0', random.choice(os_type), 'AppleWebKit/537.36',
                   '(KHTML, like Gecko)', chrome_version, 'Safari/537.36'])
      return ua
    
[2018-11-29]

NEED:
1.什么是异步、同步、阻塞、非阻塞
2.scrapy中为什么用yield

GET:
1.关系型数据库缺点
    1.存储数据库的时候需要提前建表，数据的复杂度越高，所建表的数量也越来越多，非关系型数据库不需要；
    2.增删字段是一件非常麻烦的事情，特别是数据量非常大的表，增删字段特别麻烦；
    
2.mongodb的优势
    1.易扩展：数据之间无关系，非常容易扩展；
    2.大数据量，高性能：非常高的读写性能，数据结构简单；
    3.不需要事先为要存储的数据建立字段，随时存储自定义的数据格式；
  
3.电脑已连接网线无Internet
    1.右击电脑图表点击打开网络和共享中心；
    2.选择属性进入新窗口；
    3.现在自动获取IP，自动获取DNS解析；
    4.确定完成；
