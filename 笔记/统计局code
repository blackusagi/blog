import requests
from lxml import etree
from fake_useragent import UserAgent
import pymysql

ua = UserAgent()
headers = {'User-Agent': ua.random}
urls = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2018/15/09/150928.html'


def connection():
    db = pymysql.connect(host='localhost', user='root', password='123456', db='python', charset='utf8')
    return db


def request(url):
    if len(url) < 1:
        print('URL Error')
        return None
    else:
        response = requests.get(url, headers=headers)
        response.encoding = response.apparent_encoding
        html = etree.HTML(response.text)
        # print(response.text)
    return html


def data():
    name_lis = []
    link_lis = []
    select = request(urls).xpath('//*[@class="towntr"]')
    for d in select:
        pin_url = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2018/15/09/'
        p_name = d.xpath('td/a/text()')
        href = pin_url + d.xpath('td/a/@href')[1]
        # print(href)
        # new_href = [pin_url + i for i in href]
        name_lis.append(p_name)
        link_lis.append(href)
    result = zip(name_lis, link_lis)
    return result


def parse():
    conn = connection()
    for j in data():
        html = request(j[1])
        select = html.xpath('//*[@class="villagetr"]')
        for d in select:
            con = conn.cursor()
            sql = "insert into houqi(q_name,j_name,j_code,q_code) values(%s,%s,%s,%s)"
            code = d.xpath('td[1]/text()')
            p_name = d.xpath('td[3]/text()')
            print(j[0][1], p_name, code, j[0][0])
            params = (j[0][1], p_name, code, j[0][0])
            con.execute(sql, params)
            conn.commit()
    conn.close()


parse()
